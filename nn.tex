\section{Что-то про нейронки}

Наверное надо подходить с того, что мы будем использовать 

Мол сначала в ргбд есть такие-то подходы и такие модели. Мы рассматрвиаем одну из - ббс нет. Это нейронка, которая состоит из блаблабла

И вот теперь можно поподробней про свёртку, функцию активации и про части самой сетки.

\subsection{Про бекбоны}

\subsection{Функции потерь}

Для тренировки нейронных сетей используют различные алгоритмы, основанные на стохастическом градиентном спуске,
для максимизации или минимизации некоторой целевой функции. В качестве целевой функции используют различные функции потерь, 
которые нужно минимизировать. Вид этих функций зависит от типа решаемой задачи, а выбор подходящей функции напрямую влияет на 
качество обучаемой модели. 

Для решения задачи выявления самых заметных объектов на изображении 
во многих работах [неплохо бы ссылочки], в том числе и в исследуемой нами \cite{BBS}, применяется функция бинарной перекрёстной энтропии.

В результате работы модели мы ожидаем получить бинарной изображение, которое содержит выделение наиболее заметных областей. 
Другими словами, мы хотим классифицировать каждый пиксель на изображении и отнести его либо к группе "выделяющихся", либо "не выделяющихся". То есть,
решить задачу сегментации - классификации пикселей на изображении. Таким образом, использование бинарной перекрестной энтропии 
в качестве функции потерь вполне естественно.

Однако, за последние годы для улучшения результатов задачи сегментации изображений были предложены и другие функции потерь, подходящие для 
этой задачи \cite{Loss-Functions}. Среди них : 

\begin{itemize}
    \item Dice Loss \cite{Dice-Loss}
    \item Jaccard Loss(Intersection over Union) \cite{IoU-Loss}
    \item Focal Loss \cite{Focal-Loss}
\end{itemize}

Мы проведём эксперименты с использованием каждой из функций и сравним результаты, полученные при использовании бинарной перекрёстной энтропии.
Остановимся подробнее на каждой из приведённых функций.

\subsubsection{Бинарная Перекрёстная Энтропия}

Функция бинарной перекрёстной энтропии(binary cross entropy) является частным случаем функции перекрёстной энтропии - одной из самых популярных 
функций потерь для задач классификации и, как следствие, сегментации - попиксельной классификации.

Перекрёстная энтропия \cite{CE} определяется следующим образом: 
\begin{equation}
    L_{CE} = -\sum_{i=1}^{C}y_c\log{\hat{y_c}}
\end{equation}
где $y$ - истинный класс объекта, $y_c$ - предсказанный класс, а $C$ - количество 
всех классов.

В случае предсказания только двух классов, то есть при $C=2$, 
и возможных значениях меток $y \in \{0,1\}$
перекрёстная энтропия превращается в бинарную:

\begin{equation}
    L_{CE} = -\sum_{i=1}^{2}y_c\log{\hat{y_c}} = 
    -(y\log{\hat{y}} + (1-y)\log{1-\hat{y}})
\end{equation}


\subsubsection{Dice Loss} 

\subsubsection{IoU Loss}

\subsubsection{Focal Loss}


\subsection{Метрики Качества}
