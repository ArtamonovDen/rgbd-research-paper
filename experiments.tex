\section{Эксперименты}

\subsection{Чего мы улучшали}


Чё мы сосбственно делали. что и зачем хммммммммммммммммммммммммммм
 
мы пытались улучшуть BBS Net:
-  сделать модель легче - как это формализовать интересно. 
- улучшить метрики 

резнет тип уже не сота и есть более современные решения?



\subsection{Датасеты}

С растущим интересом к задаче RGB-SOD, а также с распространением устройств, способных 
снимать изображением с картой глубины, за последние несколько лет появилось несколько RGB-D SOD датасетов.

Каждый датасет состоит из изображения с соответствующей ему картой глубины, а также
бинарное изображение с маской искомого выделяющегося объекта на изображении.

//TODO побольше про девайсы расписать!

// TODO примерчик с картиночками

//TODO описание поподробней бы

Ниже представлен краткий обзор существующих датасетов:
\begin{itemize}
    \item STERE \cite{STERE} - первый датасет со стереоскопическими изображениями, собранных с сайтов Flickr, NVIDIA 3D Vision Live и Stereoscopic Image Gallery
    Содержит 1000 изображений с различными разрешениями // TODO: добавить ссылки-сноски
    \item GIT \cite{GIT} - содержит 80 картинок домашней обстановки, собранных роботом.
    \item DES \cite{DES} - небольшой датасет объёмом 135 изображений, собранных с помошью Microsoft Kinect. Разрешение изображений: 640х480.
    \item NLPR \cite{NLPR} - содержит 1000 изображений разрешением 640х480, также собранных с помошью Microsoft Kinect.
    \item NJU2K \cite{NJU2K} - самый большой датасет, содержащий 1985 изображений с разными разрешениями, собранных из интернета, 3D фильмов и снятых на стерео камеру Fuji W3.
    \item SSD \cite{SSD} - содержит 80 картинок с высоким разрешением 960х1080, собранных из 3D фильмов.
    \item DUT-RGBD \cite{DUT} - содержит 1200 изображений со сложными для модели факторами, например: однотипный передний план или похожие передние и задние планы
    \item SIP \cite{Rethinking-RGBD} - содержит 1000 изображений с разрешением 992х744, снятых на смартфон
\end{itemize}

В таблице [ссылка на таблицу] представлены характеристики датасетов, год выхода, количество изображений и их разрешение.

// TODO таблчика как в https://arxiv.org/pdf/2008.00230.pdf или в https://arxiv.org/pdf/1907.06781.pdf

\subsection{Описание эксперимента}

С чего же начать???

% ----
Имплементация моделей, код для тренировки и валидации, функций потерь и метрик качества были написаны на языке Python 3.8
с использованием фреймворка для глубокого обучения Pytorch 1.8.0\cite{Pytorch}.

% про ббс 
В работе была использована оригинальная имплементация модели от авторов статьи \cite{BBS}, которая доступна на GitHub [ссылка!].
На её основе была написана модель BBS-Net, которая в качестве свёрточной сети для извлечения признаков
использовала сеть EfficientNet-B0 \cite{Efficientnet} с весами, предобученными на датасете ImageNet.\footnote{\url{https://github.com/lukemelas/EfficientNet-PyTorch}} 



Все модели тренировались и валидировались на датасете NJU2K предварительно разделённым на NJU2K\_TRAIN для тренировки, 
который содержит 1485 изображений, и NJU2K\_TRAIN для промежуточной валидации, содержащий 500 изображений.
Каждая тренировка состояла из 150 эпох с размером пакета(batch size) равным 10. В конце каждой эпохи запускалась валидация: рассчитывалось среднее
значение функции потерь и средней абсолютной ошибки(MAE), минимальное значение которой сохраняется и обновляется во время
всего процесса тренировки. В случае обновления значения - текущее состояние модели сохраняется и помечается наилучшим в смысле качества обучения.
В результате тренировки мы получаем модель, которая показывает наименьшую ошибку на валидационном датасете. Такая стратегия используется для того,
чтобы избежать переобучения под тренировочный датасет. 
Для тренировки модели использовался стандартный оптимизатор Adam\cite{Adam}. Начальное значение параметра скорости обучения(learning rate) 
равно 0.0001. Каждые 60 эпох значение уменьшалось в 10 раз \ref{fig:lr}. Такой подход был предложен в оригинальной работе \cite{BBS}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{lr}
    \caption{Изменения скорости обучения при тренировке}
    \label{fig:lr}
\end{figure}

На вход модели подаются RGB изображение и карта глубины с разрешением 352х352 как на этапе тренировки, там и на этапе расчёта тестовых метрик.
Так как изображения в датасетах имеют разные размеры, перед передачей применяется изменение размера, а также, на этапе тренировки, некоторые приёмы аугментации 
изображения: поворот, масштабирование, кроп. Все преобразования выполняются через стандартные классы для работы с данными в Pytorch: Dataset и DataLoader
\footnote{\url{https://pytorch.org/docs/stable/data.html}}
Все эксперименты проводились на платформе Google Colab\footnote{\url{https://colab.research.google.com/notebooks/intro.ipynb}}
с GPU Tesla P100-PCIE-16GB.



%Таблчика с экспериментами

\begin{center}
    \begin{table}
        \begin{tabular}{ |c c|c|c|c|c|c|c|c|c| } 
            \hline
            \multirow{2}{*}{\rotatebox[origin=c]{90}{Датасет}} & \multirow{2}{*}{Метрика} & \multicolumn{4}{ |c| }{ResNet} & \multicolumn{4}{ |c| }{EfficientNet} \\
            \cline{3-10}
            & & BCE & focal & dice & IoU & BCE & focal & dice & IoU\\
            \hline
            \multirow{2}{*}{\rotatebox[origin=c]{90}{NJU2K}} & mae $\downarrow$ &0,033&0,06&0,031&0,032&0,035&0.057&0,031&\textbf{0,030} \\
            & f1  $\uparrow$ &0,909&0,832&\textbf{0,920}&0,915&0,901&0.842&0,916&0,918\\
            \multirow{2}{*}{\rotatebox[origin=c]{90}{NLPR}} & mae $\downarrow$ &0,041&0,065&0,040&0,037&0,040&0.059&0,039&\textbf{0,034} \\
            & f1  $\uparrow$ &0,840&0,734&0,856&0,858&0,838&0.756&0,846&\textbf{0,865}\\
            \multirow{2}{*}{\rotatebox[origin=c]{90}{DES}} & mae $\downarrow$ &0,019&0,041&0,017&\textbf{0,015}&0,019&0.039&0,016&0,016\\
            & f1  $\uparrow$ &0,916&0,819&0,930&\textbf{0,939}&0,918&0.822&0,933&0,929\\
            \multirow{2}{*}{\rotatebox[origin=c]{90}{SSD}} & mae $\downarrow$ &0,046&0,073&0,044&0,046&0,047&0.068&0,043&\textbf{0,041} \\
            & f1  $\uparrow$ &0,841&0.777&0,855&0,851&0,844&0.777&0,860&\textbf{0,863}\\
            \multirow{2}{*}{\rotatebox[origin=c]{90}{STERE}} & mae $\downarrow$ &0,039&0,066&0,037&\textbf{0,035}&0,039&0.063&0,037&0,036 \\
            & f1  $\uparrow$ &0,888&0,817&0,898&\textbf{0,905}&0,891&0.824&0,899&0,903\\   
            \multirow{2}{*}{\rotatebox[origin=c]{90}{LFSD}} & mae $\downarrow$ &0,077&0,104&\textbf{0,066}&0,072&0,074&0.102&0,082&0,072\\
            & f1  $\uparrow$ &0,843&0,782&\textbf{0,862}&0,859&0,843&0.789&0,834&0,851\\  
            \multirow{2}{*}{\rotatebox[origin=c]{90}{SIP}} & mae $\downarrow$ &0,047&0,07&0,045&0,044&0,047&0.069&0,051&\textbf{0,042}\\
            & f1  $\uparrow$ &0,867&0,789&0,877&0,88&0,87&0.809&0,859&\textbf{0,884}\\  
            \multirow{2}{*}{\rotatebox[origin=c]{90}{DUT}} & mae $\downarrow$ &0,121&0,145&0,116&0,121&0,112&0.122&\textbf{0,105}&0,14\\
            & f1  $\uparrow$ &0,592&0,574&0,67&0,597&0,65&0.639&0,707&\textbf{0,728}\\  
            \hline
        \end{tabular}
    \caption{Эксперименты}
    \label{tab:experiments}
    \end{table}
\end{center}



