\section{Эксперименты}

С чего же начать???

% ----
Имплементация моделей, код для тренировки и валидации, функций потерь и метрик качества были написаны на языке Python 3.8
с использованием фреймворка для глубокого обучения Pytorch\cite{Pytorch}.

% про ббс 
В работе была использована оригинальная имплементации модели от авторов статьи \cite{BBS}, которая доступна на GitHub [ссылка!].
На её основе была написана модель BBS-Net, которая в качестве бэкбона использовала свёрточную нейронную сеть EfficientNet-B0 \cite{Efficientnet}.

% детали реализации надо? или описать это, когда модели описываем? 


Все модели тренировались и валидировались на датасете NJU2K предварительно разделённым на NJU2K\_TRAIN для тренировки, 
который содержит 1485 изображений, и NJU2K\_TRAIN для промежуточной валидации, содержащий 500 изображений.
Каждая тренировка состояла из 150 эпох с размером пакета(batch size) равным 10. В конце каждой эпохи запускалась валидация: рассчитывалось среднее
значение функции потерь и средней абсолютной ошибки(MAE), минимальное значение которой сохраняется и обновляется во время
всего процесса тренировки. В случае обновления значения - текущее состояние модели сохраняется и помечается наилучшим в смысле качества обучения.
В результате тренировки мы получаем модель, которая показывает наименьшую ошибку на валидационном датасете. Такая стратегия используется для того,
чтобы избежать переобучения под тренировочный датасет. 
Для тренировки модели использовался стандартный оптимизатор Adam\cite{Adam}. Начальное значение параметра скорости обучения(learning rate) 
равно 0.0001. Каждые 60 эпох значение уменьшалось в 10 раз \ref{fig:lr}. Такой подход был предложен в оригинальной работе \cite{BBS}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{lr}
    \caption{Изменения скорости обучения при тренировке}
    \label{fig:lr}
\end{figure}

На вход модели подаются RGB изображение и карта глубины с разрешением 352х352 как на этапе тренировки, там и на этапе расчёта тестовых метрик.
Так как изображения в датасетах имеют разные размеры, перед передачей применяется изменение размера, а также, на этапе тренировки, некоторые приёмы аугментации 
изображения: поворот, масштабирование, кроп. Все преобразования выполняются через стандартные классы для работы с данными в Pytorch: Dataset и DataLoader
\footnote{\url{https://pytorch.org/docs/stable/data.html}}
Все эксперименты проводились на платформе Google Colab\footnote{\url{https://colab.research.google.com/notebooks/intro.ipynb}}
с GPU Tesla P100-PCIE-16GB.



%Таблчика с экспериментами

\begin{center}
    \begin{tabular}{ |c c|c|c|c|c|c|c|c|c| } 
    \hline
    \multicolumn{10}{ |c| }{Эксперименты} \\
    \hline
    \multirow{2}{*}{\rotatebox[origin=c]{90}{Датасет}} & \multirow{2}{*}{Метрика} & \multicolumn{4}{ |c| }{ResNet} & \multicolumn{4}{ |c| }{EfficientNet} \\
     \cline{3-10}
     & & BCE & focal & dice & IoU & BCE & focal & dice & IoU\\
     \hline
     \multirow{2}{*}{\rotatebox[origin=c]{90}{DES}} & mae $\downarrow$ & 0,031 & & 0,017 & & 0,031 & & 0,017 & \\
      & f1  $\uparrow$ & \textbf{0,920} & 0,930 & 0,855 & & 0,920 & 0,930 & 0,855 &\\
     \hline

    %   \multirow{2}{*}{\rotatebox[origin=c]{90}{rota}}
    \end{tabular}
\end{center}



